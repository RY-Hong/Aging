{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Final_32_features.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    traindata = list(reader)\n",
    "del(traindata[0])\n",
    "for i in traindata:\n",
    "    for j in range(32):\n",
    "        i[j] = float(i[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('supplementary_predictions/GO_aging_and_GenAge_ageing_labels.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    trainlabels = list(reader)\n",
    "del(trainlabels[0])\n",
    "for i in range(len(trainlabels)):\n",
    "    trainlabels[i] = float(trainlabels[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yxs\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:25:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "classifier0 =XGBClassifier(max_depth=1, learning_rate=0.3, n_estimators=50)\n",
    "classifier0.fit(np.array(traindata), np.array(trainlabels))\n",
    "xgb_predictions = []\n",
    "for e in traindata:\n",
    "    xgb_predictions.append(classifier0.predict_proba(np.array(e).reshape(1,-1))[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "classifier1 = SVC(probability=True)\n",
    "classifier1.fit(traindata, trainlabels)\n",
    "svm_predictions = []\n",
    "for e in traindata:\n",
    "    svm_predictions.append(classifier1.predict_proba(np.array(e).reshape(1,-1))[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "classifier2 = LogisticRegression()\n",
    "classifier2.fit(traindata, trainlabels)\n",
    "lg_predictions = []\n",
    "for e in traindata:\n",
    "    lg_predictions.append(classifier2.predict_proba(np.array(e).reshape(1,-1))[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_predictions = (np.array(xgb_predictions) + np.array(svm_predictions) + np.array(lg_predictions)) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of 20 proteins with largest probabilities to be ageing related are:\n",
      "[15862, 12383, 5123, 663, 6259, 19108, 13777, 1600, 12671, 12531, 5376, 6258, 8420, 17314, 10076, 2270, 173, 1775, 19172, 16152]\n",
      "Their corresponding probabilities are:\n",
      "[0.9961253295512132, 0.9919101757239425, 0.9893481154324721, 0.9881214570659465, 0.9804163086145562, 0.9799098908596443, 0.9761202016149052, 0.9741084646593862, 0.9737451592123515, 0.9711189525464089, 0.9697612627997172, 0.9687703145679228, 0.9583373959931545, 0.9573151434742787, 0.9561017805874684, 0.9546543435111193, 0.9513574878893908, 0.9455097378676701, 0.9415402709882897, 0.9349140212883865]\n"
     ]
    }
   ],
   "source": [
    "idx_20_max = list(map(list(ave_predictions).index, heapq.nlargest(20, ave_predictions)))\n",
    "val_20_max = heapq.nlargest(20, ave_predictions)\n",
    "print(\"Indices of 20 proteins with largest probabilities to be ageing related are:\")\n",
    "print(idx_20_max)\n",
    "print(\"Their corresponding probabilities are:\")\n",
    "print(val_20_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
